{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start with loading the glove embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "#import rich\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "#import transformers\n",
    "#import tokenizers\n",
    "#import datasets\n",
    "#import zipfile\n",
    "#from huggingface_hub import hf_hub_download\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400001/400001 [00:08<00:00, 49579.60it/s]\n"
     ]
    }
   ],
   "source": [
    "target_file = \"glove.6B.50d.txt\"\n",
    "vocabulary = []\n",
    "vectors = []\n",
    "emb_dic = {}\n",
    "with open(target_file, \"r\", encoding=\"utf8\") as f:\n",
    "    for l in tqdm(f.readlines() ):\n",
    "        word, *vector = l.split()\n",
    "        vocabulary.append(word)\n",
    "        vector_t = torch.tensor([float(v) for v in vector])\n",
    "        vectors.append(vector_t)\n",
    "        emb_dic[word] = vector_t\n",
    "vectors = torch.stack(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# somtehing from week 4\n",
    "class NewsEncoder(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.activation_fn = nn.ReLU\n",
    "\n",
    "        #self.l_1 = nn.Linear(in_features=int(features_cat_size),\n",
    "        #                  out_features=l_1_hidden_size)\n",
    "        \n",
    "\n",
    "    def forward(self, x): # x is a string of words - title\n",
    "        words = x.split(\" \")\n",
    "        vectors = []\n",
    "        for word in words:\n",
    "            print(word)\n",
    "            vectors.append(torch.Tensor(emb_dic[word.lower()]))\n",
    "        #features_final = self.l_1(x)\n",
    "        e_s = torch.stack(vectors)\n",
    "        scaled_dot = nn.functional.scaled_dot_product_attention(e_s,e_s,e_s)\n",
    "        return scaled_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NewsEncoder(0) # TODO - I need to change this with a number that will correspond to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = \"Breaking news about this\"\n",
    "test2 = \"This has happened again\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breaking\n",
      "news\n",
      "about\n",
      "this\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0157e-02,  2.4989e-01,  4.3846e-02,  1.5625e-01,  2.2384e-01,\n",
       "          6.2950e-02, -3.3575e-01, -1.8143e-02, -1.0717e-01,  4.8769e-03,\n",
       "         -4.0176e-01, -3.0917e-01, -6.1963e-01,  6.2024e-02,  8.9128e-01,\n",
       "         -9.4411e-03, -2.2247e-01, -2.6615e-01, -4.3537e-01, -1.8817e-01,\n",
       "          2.5553e-01,  4.0876e-01,  3.6024e-01, -5.7414e-02,  4.3141e-01,\n",
       "         -1.6105e+00, -1.9780e-01,  2.5115e-01,  4.7579e-01, -4.5814e-03,\n",
       "          3.3320e+00,  2.1369e-02,  5.6244e-02, -1.5367e-01, -5.2320e-01,\n",
       "         -1.7383e-01, -3.3079e-02, -6.0352e-02,  6.2080e-04, -6.7409e-02,\n",
       "         -8.9417e-02,  1.3494e-01,  2.8677e-02,  2.5934e-01,  4.0715e-03,\n",
       "          1.2172e-01,  3.7067e-03,  2.5722e-01, -2.0290e-01, -2.9370e-02],\n",
       "        [-3.2087e-02,  4.4404e-01,  4.0762e-01,  7.8165e-01,  3.1579e-02,\n",
       "         -8.1479e-01, -1.0370e+00, -1.5414e-01, -1.2605e-01, -5.7964e-01,\n",
       "         -4.1474e-01, -2.5222e-01, -3.8301e-01,  2.3935e-01,  1.0095e+00,\n",
       "          1.1953e-01, -1.0602e+00, -1.6557e-01, -2.6893e-01,  2.3331e-01,\n",
       "          7.6831e-01,  7.7914e-01,  7.6191e-01,  4.1638e-01,  4.8365e-01,\n",
       "         -1.7323e+00, -5.8773e-01,  4.9049e-01,  1.1332e-02,  3.6544e-01,\n",
       "          3.4095e+00,  2.2921e-02,  3.3711e-01, -4.1797e-01, -9.6939e-01,\n",
       "         -4.4492e-01, -2.9329e-01, -5.0686e-01,  1.0086e-01,  4.1777e-02,\n",
       "          4.8615e-01,  4.5725e-01, -6.1834e-02, -2.6782e-01,  1.6114e-01,\n",
       "          2.3706e-01, -4.7098e-01,  1.1880e+00,  3.1422e-01,  5.8656e-01],\n",
       "        [ 5.2373e-01,  3.6981e-01,  2.1904e-01, -7.3042e-03,  4.0399e-01,\n",
       "         -3.1438e-02, -5.0994e-01, -3.1865e-01, -3.3412e-01, -8.8608e-02,\n",
       "         -6.1625e-01, -3.2428e-01, -2.6689e-01, -3.5259e-01,  1.1834e+00,\n",
       "          6.9627e-02, -3.2041e-01,  1.1171e-01, -5.1680e-01, -2.3493e-01,\n",
       "          3.0348e-01,  6.4842e-01,  6.4625e-01, -3.4104e-03,  5.5334e-01,\n",
       "         -1.7738e+00, -4.2027e-01,  3.1540e-01,  3.4722e-01,  1.7677e-02,\n",
       "          3.5984e+00,  3.3488e-02,  3.4831e-02, -3.2404e-01, -3.9407e-01,\n",
       "         -4.2693e-01, -3.5230e-01, -2.2465e-01,  2.3540e-01, -1.4844e-02,\n",
       "         -7.3541e-02,  3.4210e-01,  2.0536e-01,  3.2021e-01, -5.0258e-02,\n",
       "          8.9208e-02, -1.0839e-01,  6.0263e-01, -2.8124e-01,  2.1016e-01],\n",
       "        [ 3.7990e-01,  3.6841e-01,  5.7101e-03,  1.5950e-01,  3.5736e-01,\n",
       "         -2.3856e-02, -4.6047e-01, -2.5790e-01, -1.9996e-01, -6.3639e-02,\n",
       "         -3.9063e-01, -1.7226e-01, -4.1324e-01, -1.8572e-01,  1.0037e+00,\n",
       "          1.6670e-01, -1.7518e-01, -9.2442e-02, -4.5204e-01, -2.0235e-01,\n",
       "          2.0683e-01,  3.1885e-01,  4.6392e-01,  5.3141e-02,  5.2999e-01,\n",
       "         -1.7318e+00, -5.6261e-01,  3.0931e-01,  3.5509e-01,  5.3123e-02,\n",
       "          3.6782e+00, -6.2246e-02, -6.5513e-03, -4.0553e-01, -3.6774e-01,\n",
       "         -3.3532e-01, -1.1739e-01, -9.5475e-02,  2.7734e-02, -6.5306e-02,\n",
       "         -8.0986e-02,  2.2020e-01, -4.5482e-02,  1.4041e-01, -8.2775e-02,\n",
       "          1.7382e-01, -5.2354e-02,  5.0687e-01, -6.3483e-02,  2.2046e-01]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> 2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43moptim\u001b[49m\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m)\u001b[38;5;66;03m#, weight_decay=0.3)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optim' is not defined"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)#, weight_decay=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the forward pass with dummy data\n",
    "out = model([])\n",
    "print(\"Output shape:\", out.size())\n",
    "print(f\"Output logits:\\n{out.detach().cpu().numpy()}\")\n",
    "print(f\"Output probabilities:\\n{out.softmax(1).detach().cpu().numpy()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
